{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta,date\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np \n",
    "import os.path\n",
    "\n",
    "class ReportTM:\n",
    "    \n",
    "    def generate_DF(self,name_file):\n",
    "        with open('data/'+name_file, encoding='utf-8') as fh:\n",
    "            data = json.load(fh)\n",
    "\n",
    "        price_date_name = 'currentPrice_'+str(name_file[:-5])\n",
    "        Data_products = {\n",
    "            \"id\" : [],\n",
    "            'colorDescription' : [],\n",
    "            'portrait_url' : [],\n",
    "            'squarishURL' : [],\n",
    "            'Stock' : [],\n",
    "            'isNew' : [],\n",
    "            price_date_name : [],\n",
    "            'fullPrice' : [],\n",
    "            'subtitle' : [],\n",
    "            'title' : [],\n",
    "            'date':[],\n",
    "            'url':[]\n",
    "        }\n",
    "\n",
    "        for product in data:\n",
    "            Data_products['id'].append(product['id'])\n",
    "            Data_products['colorDescription'].append(product['colorDescription'])\n",
    "            Data_products['portrait_url'].append(product['images']['portraitURL'])\n",
    "            Data_products['squarishURL'].append(product['images']['squarishURL'])\n",
    "            Data_products['Stock'].append(product['inStock'])\n",
    "            Data_products['isNew'].append(product['colorways'][0]['isNew'])\n",
    "            Data_products[price_date_name].append(product['price']['currentPrice'])\n",
    "            Data_products['fullPrice'].append(product['price']['fullPrice'])\n",
    "            Data_products['subtitle'].append(product['subtitle'])\n",
    "            Data_products['title'].append(product['title'])\n",
    "            Data_products['date'].append(name_file[:-5])\n",
    "            Data_products['url'].append(product['url'])\n",
    "        \n",
    "        return pd.DataFrame(Data_products)\n",
    "\n",
    "    def generate_time_serie(self,*files):\n",
    "        array_dataframes =[]\n",
    "        for file in files:\n",
    "            with open('data/'+file, encoding='utf-8') as fh:\n",
    "                data = json.load(fh)\n",
    "\n",
    "            price_date_name = file[:-5]\n",
    "            Data_products = {\n",
    "                \"id\" : [],\n",
    "                price_date_name : []\n",
    "\n",
    "            }\n",
    "\n",
    "            for product in data:\n",
    "                Data_products['id'].append(product['id'])\n",
    "                Data_products[price_date_name].append(product['price']['currentPrice'])\n",
    "            array_dataframes.append(pd.DataFrame(Data_products))\n",
    "\n",
    "        # merge a la lista de dataframes\n",
    "\n",
    "        df_final = reduce(lambda left,right: pd.merge(left,right,on='id', how='outer'), array_dataframes)\n",
    "\n",
    "        return df_final\n",
    "    \n",
    "    def check_changes_2days(self, day):\n",
    "    \n",
    "        #obtenemos el dia anterior a la fecha dada\n",
    "        date = datetime.strptime(day, \"%Y-%m-%d\")\n",
    "        modified_date = date - timedelta(days=1)\n",
    "        prev_day = datetime.strftime(modified_date, \"%Y-%m-%d\")\n",
    "        #comprobamos que existan archivos para los dos dias\n",
    "        day_file = day +'.json'\n",
    "        prev_day_file = prev_day+'.json'\n",
    "        if os.path.isfile('data/'+day_file) and os.path.isfile('data/'+prev_day_file) :\n",
    "            df_time = self.generate_time_serie(prev_day_file,day_file)\n",
    "            df_time['change'] = df_time[prev_day_file[:-5]] - df_time[day_file[:-5]]\n",
    "            return df_time.loc[df_time['change']>0]\n",
    "            #\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                    \"Nombres de archivo no validos. \"\n",
    "                        f\"Only one file per ZIP: {prev_day_file,day_file}\"\n",
    "                    )\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-06-27.json',\n",
       " '2020-06-28.json',\n",
       " '2020-06-29.json',\n",
       " '2020-06-30.json',\n",
       " '2020-07-01.json',\n",
       " '2020-07-02.json',\n",
       " '2020-07-03.json',\n",
       " '2020-07-04.json',\n",
       " '2020-07-05.json']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#obtenemos todos los dataframes port archivo en el folder\n",
    "list_dataf = glob.glob(\"data/*.json\")\n",
    "list_dataf = [z[5:] for z in list_dataf]\n",
    "list_dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info= ReportTM()\n",
    "dataframes = []\n",
    "#guardamos los dataframes\n",
    "for data in list_dataf:\n",
    "    dataframes.append(info.generate_DF(data))\n",
    "#Extraemos solo informacion importante\n",
    "df = pd.concat(dataframes, sort=False)[['id','title','portrait_url','url']]\n",
    "\n",
    "#df = \n",
    "#df.loc[df['id'] == 'eff479e3-dab9-38e3-b814-4e8b49f371d6']\n",
    "jj = df.loc[df['portrait_url'] != '']\n",
    "jj =jj.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj.to_csv('data/dic_products/products.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
